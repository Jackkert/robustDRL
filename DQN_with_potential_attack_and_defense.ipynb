{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8bbf61",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800201a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "\n",
    "EPISODES = 75\n",
    "LEARNING_RATE = 0.0001\n",
    "MEM_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.95\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_DECAY = 0.999\n",
    "EXPLORATION_MIN = 0.001\n",
    "EPSILON_PERT = 0.2\n",
    "\n",
    "FC1_DIMS = 1024\n",
    "FC2_DIMS = 512\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e224197",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_shape = env.observation_space.shape\n",
    "        self.action_space = action_space\n",
    "\n",
    "        self.fc1 = nn.Linear(*self.input_shape, FC1_DIMS)\n",
    "        self.fc2 = nn.Linear(FC1_DIMS, FC2_DIMS)\n",
    "        self.fc3 = nn.Linear(FC2_DIMS, self.action_space)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=LEARNING_RATE)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.to(DEVICE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        self.mem_count = 0\n",
    "\n",
    "        self.states = np.zeros((MEM_SIZE, *env.observation_space.shape),dtype=np.float32)\n",
    "        self.actions = np.zeros(MEM_SIZE, dtype=np.int64)\n",
    "        self.rewards = np.zeros(MEM_SIZE, dtype=np.float32)\n",
    "        self.states_ = np.zeros((MEM_SIZE, *env.observation_space.shape),dtype=np.float32)\n",
    "        self.dones = np.zeros(MEM_SIZE, dtype=np.bool)\n",
    "\n",
    "    def add(self, state, action, reward, state_, done):\n",
    "        mem_index = self.mem_count % MEM_SIZE\n",
    "\n",
    "        self.states[mem_index]  = state.clone().detach().numpy()\n",
    "        self.actions[mem_index] = action\n",
    "        self.rewards[mem_index] = reward\n",
    "        self.states_[mem_index] = state_.clone().detach().numpy()\n",
    "        self.dones[mem_index] =  1 - done\n",
    "\n",
    "        self.mem_count += 1\n",
    "\n",
    "    def sample(self):\n",
    "        MEM_MAX = min(self.mem_count, MEM_SIZE)\n",
    "        batch_indices = np.random.choice(MEM_MAX, BATCH_SIZE, replace=True)\n",
    "\n",
    "        states  = self.states[batch_indices]\n",
    "        actions = self.actions[batch_indices]\n",
    "        rewards = self.rewards[batch_indices]\n",
    "        states_ = self.states_[batch_indices]\n",
    "        dones   = self.dones[batch_indices]\n",
    "\n",
    "        return states, actions, rewards, states_, dones\n",
    "\n",
    "class DQN_Solver:\n",
    "    def __init__(self):\n",
    "        self.memory = ReplayBuffer()\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "        self.network = Network()\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        if random.random() < self.exploration_rate:\n",
    "            return env.action_space.sample(), 0.0\n",
    "\n",
    "        state = observation\n",
    "        state = state.to(DEVICE)\n",
    "        state = state.unsqueeze(0)\n",
    "\n",
    "        q_values = self.network(state.float())\n",
    "        return torch.argmax(q_values).item(), q_values\n",
    "\n",
    "    def learn(self):\n",
    "        if self.memory.mem_count < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        states, actions, rewards, states_, dones = self.memory.sample()\n",
    "        states = torch.tensor(states , dtype=torch.float32).to(DEVICE)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(DEVICE)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(DEVICE)\n",
    "        states_ = torch.tensor(states_, dtype=torch.float32).to(DEVICE)\n",
    "        dones = torch.tensor(dones, dtype=torch.bool).to(DEVICE)\n",
    "\n",
    "        batch_indices = np.arange(BATCH_SIZE, dtype=np.int64)\n",
    "        states.requires_grad = True\n",
    "        \n",
    "        q_values = self.network(states)\n",
    "        next_q_values = self.network(states_)\n",
    "\n",
    "        predicted_value_of_now = q_values[batch_indices, actions]\n",
    "        predicted_value_of_future = torch.max(next_q_values, dim=1)[0].detach()\n",
    "        \n",
    "        q_target = rewards + GAMMA * predicted_value_of_future * dones\n",
    "\n",
    "        loss = self.network.loss(q_target, predicted_value_of_now)        \n",
    "        self.network.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.network.optimizer.step()\n",
    "\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "\n",
    "    def returning_epsilon(self):\n",
    "        return self.exploration_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4616f1",
   "metadata": {},
   "source": [
    "## Training the network without defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a852a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_338/3144857995.py:29: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.dones = np.zeros(MEM_SIZE, dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Average Reward 16.0 Best Reward 16.0 Last Reward 16.0 Epsilon 1.0\n",
      "Episode 2 Average Reward 19.5 Best Reward 23.0 Last Reward 23.0 Epsilon 1.0\n",
      "Episode 3 Average Reward 18.666666666666668 Best Reward 23.0 Last Reward 17.0 Epsilon 1.0\n",
      "Episode 4 Average Reward 20.0 Best Reward 24.0 Last Reward 24.0 Epsilon 0.9831353223738244\n",
      "Episode 5 Average Reward 20.6 Best Reward 24.0 Last Reward 23.0 Epsilon 0.9607702107358118\n",
      "Episode 6 Average Reward 20.666666666666668 Best Reward 24.0 Last Reward 21.0 Epsilon 0.9407945259609451\n",
      "Episode 7 Average Reward 20.714285714285715 Best Reward 24.0 Last Reward 21.0 Epsilon 0.9212341621210596\n",
      "Episode 8 Average Reward 19.75 Best Reward 24.0 Last Reward 13.0 Epsilon 0.9093297114626595\n",
      "Episode 9 Average Reward 20.11111111111111 Best Reward 24.0 Last Reward 23.0 Epsilon 0.8886435861147077\n",
      "Episode 10 Average Reward 19.9 Best Reward 24.0 Last Reward 18.0 Epsilon 0.8727832416118043\n",
      "Episode 11 Average Reward 22.09090909090909 Best Reward 44.0 Last Reward 44.0 Epsilon 0.8351949903256736\n",
      "Episode 12 Average Reward 24.416666666666668 Best Reward 50.0 Last Reward 50.0 Epsilon 0.7944421754397457\n",
      "Episode 13 Average Reward 23.384615384615383 Best Reward 50.0 Last Reward 11.0 Epsilon 0.7857468750083979\n",
      "Episode 14 Average Reward 26.642857142857142 Best Reward 69.0 Last Reward 69.0 Epsilon 0.7333332049215037\n",
      "Episode 15 Average Reward 25.8 Best Reward 69.0 Last Reward 14.0 Epsilon 0.7231330071735643\n",
      "Episode 16 Average Reward 25.25 Best Reward 69.0 Last Reward 17.0 Epsilon 0.7109376021267352\n",
      "Episode 17 Average Reward 26.176470588235293 Best Reward 69.0 Last Reward 41.0 Epsilon 0.6823646221455009\n",
      "Episode 18 Average Reward 25.333333333333332 Best Reward 69.0 Last Reward 11.0 Epsilon 0.674896028990821\n",
      "Episode 19 Average Reward 25.31578947368421 Best Reward 69.0 Last Reward 25.0 Epsilon 0.6582245533155777\n",
      "Episode 20 Average Reward 25.2 Best Reward 69.0 Last Reward 23.0 Epsilon 0.6432507594921204\n",
      "Episode 21 Average Reward 25.80952380952381 Best Reward 69.0 Last Reward 38.0 Epsilon 0.6192540566123834\n",
      "Episode 22 Average Reward 29.545454545454547 Best Reward 108.0 Last Reward 108.0 Epsilon 0.5558294947876746\n",
      "Episode 23 Average Reward 32.869565217391305 Best Reward 108.0 Last Reward 106.0 Epsilon 0.4999002346477277\n",
      "Episode 24 Average Reward 32.458333333333336 Best Reward 108.0 Last Reward 23.0 Epsilon 0.4885281230967259\n",
      "Episode 25 Average Reward 36.0 Best Reward 121.0 Last Reward 121.0 Epsilon 0.43282630302490405\n",
      "Episode 26 Average Reward 41.26923076923077 Best Reward 173.0 Last Reward 173.0 Epsilon 0.36403497277104113\n",
      "Episode 27 Average Reward 43.25925925925926 Best Reward 173.0 Last Reward 95.0 Epsilon 0.3310278167522081\n",
      "Episode 28 Average Reward 50.07142857142857 Best Reward 234.0 Last Reward 234.0 Epsilon 0.2619321058792933\n",
      "Episode 29 Average Reward 59.03448275862069 Best Reward 310.0 Last Reward 310.0 Epsilon 0.1920835106763006\n",
      "Episode 30 Average Reward 69.7 Best Reward 379.0 Last Reward 379.0 Epsilon 0.13146499289819583\n",
      "Episode 31 Average Reward 77.51612903225806 Best Reward 379.0 Last Reward 312.0 Epsilon 0.09621492569550721\n",
      "Episode 32 Average Reward 84.0625 Best Reward 379.0 Last Reward 287.0 Epsilon 0.07220006185805601\n",
      "Episode 33 Average Reward 88.48484848484848 Best Reward 379.0 Last Reward 230.0 Epsilon 0.05735877420939828\n",
      "Episode 34 Average Reward 93.94117647058823 Best Reward 379.0 Last Reward 274.0 Epsilon 0.04360573744759213\n",
      "Episode 35 Average Reward 104.45714285714286 Best Reward 462.0 Last Reward 462.0 Epsilon 0.027466239073575264\n",
      "Episode 36 Average Reward 110.02777777777777 Best Reward 462.0 Last Reward 305.0 Epsilon 0.020242917487556054\n",
      "Episode 37 Average Reward 118.02702702702703 Best Reward 462.0 Last Reward 406.0 Epsilon 0.01348532211528074\n",
      "Episode 38 Average Reward 122.42105263157895 Best Reward 462.0 Last Reward 285.0 Epsilon 0.010139708479233867\n",
      "Episode 39 Average Reward 126.71794871794872 Best Reward 462.0 Last Reward 290.0 Epsilon 0.007586073646469628\n",
      "Episode 40 Average Reward 131.075 Best Reward 462.0 Last Reward 301.0 Epsilon 0.005613439038297721\n",
      "Episode 41 Average Reward 136.6341463414634 Best Reward 462.0 Last Reward 359.0 Epsilon 0.003919577750388748\n",
      "Episode 42 Average Reward 141.28571428571428 Best Reward 462.0 Last Reward 332.0 Epsilon 0.002811780241127761\n",
      "Episode 43 Average Reward 145.02325581395348 Best Reward 462.0 Last Reward 302.0 Epsilon 0.0020785420693913413\n",
      "Episode 44 Average Reward 150.47727272727272 Best Reward 462.0 Last Reward 385.0 Epsilon 0.001414072856624763\n",
      "Episode 45 Average Reward 152.6888888888889 Best Reward 462.0 Last Reward 250.0 Epsilon 0.0011011433047009515\n",
      "Episode 46 Average Reward 156.41304347826087 Best Reward 462.0 Last Reward 324.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 158.3404255319149 Best Reward 462.0 Last Reward 247.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 162.08333333333334 Best Reward 462.0 Last Reward 338.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 164.0204081632653 Best Reward 462.0 Last Reward 257.0 Epsilon 0.001\n",
      "Episode 50 Average Reward 167.04 Best Reward 462.0 Last Reward 315.0 Epsilon 0.001\n",
      "Episode 51 Average Reward 170.80392156862746 Best Reward 462.0 Last Reward 359.0 Epsilon 0.001\n",
      "Episode 52 Average Reward 175.3846153846154 Best Reward 462.0 Last Reward 409.0 Epsilon 0.001\n",
      "Episode 53 Average Reward 179.1320754716981 Best Reward 462.0 Last Reward 374.0 Epsilon 0.001\n",
      "Episode 54 Average Reward 181.53703703703704 Best Reward 462.0 Last Reward 309.0 Epsilon 0.001\n",
      "Episode 55 Average Reward 183.05454545454546 Best Reward 462.0 Last Reward 265.0 Epsilon 0.001\n",
      "Episode 56 Average Reward 184.05357142857142 Best Reward 462.0 Last Reward 239.0 Epsilon 0.001\n",
      "Episode 57 Average Reward 186.5438596491228 Best Reward 462.0 Last Reward 326.0 Epsilon 0.001\n",
      "Episode 58 Average Reward 188.29310344827587 Best Reward 462.0 Last Reward 288.0 Epsilon 0.001\n",
      "Episode 59 Average Reward 190.8135593220339 Best Reward 462.0 Last Reward 337.0 Epsilon 0.001\n",
      "Episode 60 Average Reward 193.4 Best Reward 462.0 Last Reward 346.0 Epsilon 0.001\n",
      "Episode 61 Average Reward 195.49180327868854 Best Reward 462.0 Last Reward 321.0 Epsilon 0.001\n",
      "Episode 62 Average Reward 197.2741935483871 Best Reward 462.0 Last Reward 306.0 Epsilon 0.001\n",
      "Episode 63 Average Reward 198.87301587301587 Best Reward 462.0 Last Reward 298.0 Epsilon 0.001\n",
      "Episode 64 Average Reward 201.3125 Best Reward 462.0 Last Reward 355.0 Epsilon 0.001\n",
      "Episode 65 Average Reward 203.41538461538462 Best Reward 462.0 Last Reward 338.0 Epsilon 0.001\n",
      "Episode 66 Average Reward 205.78787878787878 Best Reward 462.0 Last Reward 360.0 Epsilon 0.001\n",
      "Episode 67 Average Reward 207.0597014925373 Best Reward 462.0 Last Reward 291.0 Epsilon 0.001\n",
      "Episode 68 Average Reward 209.01470588235293 Best Reward 462.0 Last Reward 340.0 Epsilon 0.001\n",
      "Episode 69 Average Reward 210.42028985507247 Best Reward 462.0 Last Reward 306.0 Epsilon 0.001\n",
      "Episode 70 Average Reward 213.0 Best Reward 462.0 Last Reward 391.0 Epsilon 0.001\n",
      "Episode 71 Average Reward 213.43661971830986 Best Reward 462.0 Last Reward 244.0 Epsilon 0.001\n",
      "Episode 72 Average Reward 214.13888888888889 Best Reward 462.0 Last Reward 264.0 Epsilon 0.001\n",
      "Episode 73 Average Reward 215.65753424657535 Best Reward 462.0 Last Reward 325.0 Epsilon 0.001\n",
      "Episode 74 Average Reward 216.97297297297297 Best Reward 462.0 Last Reward 313.0 Epsilon 0.001\n"
     ]
    }
   ],
   "source": [
    "agent = DQN_Solver()\n",
    "agent.network.train()\n",
    "\n",
    "best_reward = 0\n",
    "average_reward = 0\n",
    "episode_number = []\n",
    "average_reward_number = []\n",
    "\n",
    "for i in range(1, EPISODES):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "\n",
    "    while True:\n",
    "        action, q_values = agent.choose_action(state)\n",
    "        \n",
    "        state_, reward, done, info = env.step(action)\n",
    "        agent.memory.add(state, action, reward, state_, done)\n",
    "        agent.learn()\n",
    "        state = state_\n",
    "        score += reward\n",
    "\n",
    "        if done:\n",
    "            if score > best_reward:\n",
    "                best_reward = score\n",
    "            average_reward += score\n",
    "            print(\"Episode {} Average Reward {} Best Reward {} Last Reward {} Epsilon {}\".format(i, average_reward/i, best_reward, score, agent.returning_epsilon()))\n",
    "            break\n",
    "\n",
    "        episode_number.append(i)\n",
    "        average_reward_number.append(average_reward/i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23966e",
   "metadata": {},
   "source": [
    "## Testing the network with FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560186e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joostbankras/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 Average Reward 230.0 Best Reward 230.0 Last Reward 230.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 198.0 Best Reward 230.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 222.0 Best Reward 270.0 Last Reward 270.0 Epsilon 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joostbankras/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py:151: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4 Average Reward 206.0 Best Reward 270.0 Last Reward 158.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 202.2 Best Reward 270.0 Last Reward 187.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 201.16666666666666 Best Reward 270.0 Last Reward 196.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 199.28571428571428 Best Reward 270.0 Last Reward 188.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 195.625 Best Reward 270.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 198.66666666666666 Best Reward 270.0 Last Reward 223.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 198.0 Best Reward 270.0 Last Reward 192.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 198.0 Best Reward 270.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 197.0 Best Reward 270.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 203.53846153846155 Best Reward 282.0 Last Reward 282.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 203.92857142857142 Best Reward 282.0 Last Reward 209.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 207.2 Best Reward 282.0 Last Reward 253.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 207.75 Best Reward 282.0 Last Reward 216.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 204.2941176470588 Best Reward 282.0 Last Reward 149.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 207.22222222222223 Best Reward 282.0 Last Reward 257.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 206.10526315789474 Best Reward 282.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 205.1 Best Reward 282.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 204.1904761904762 Best Reward 282.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 202.95454545454547 Best Reward 282.0 Last Reward 177.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 203.47826086956522 Best Reward 282.0 Last Reward 215.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 202.625 Best Reward 282.0 Last Reward 183.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 204.6 Best Reward 282.0 Last Reward 252.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 203.65384615384616 Best Reward 282.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 202.85185185185185 Best Reward 282.0 Last Reward 182.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 203.67857142857142 Best Reward 282.0 Last Reward 226.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 204.17241379310346 Best Reward 282.0 Last Reward 218.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 204.96666666666667 Best Reward 282.0 Last Reward 228.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 204.06451612903226 Best Reward 282.0 Last Reward 177.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 203.65625 Best Reward 282.0 Last Reward 191.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 203.84848484848484 Best Reward 282.0 Last Reward 210.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 202.47058823529412 Best Reward 282.0 Last Reward 157.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 202.88571428571427 Best Reward 282.0 Last Reward 217.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 202.30555555555554 Best Reward 282.0 Last Reward 182.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 201.40540540540542 Best Reward 282.0 Last Reward 169.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 202.18421052631578 Best Reward 282.0 Last Reward 231.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 202.76923076923077 Best Reward 282.0 Last Reward 225.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 206.0 Best Reward 332.0 Last Reward 332.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 205.6341463414634 Best Reward 332.0 Last Reward 191.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 206.16666666666666 Best Reward 332.0 Last Reward 228.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 205.97674418604652 Best Reward 332.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 205.97727272727272 Best Reward 332.0 Last Reward 206.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 205.44444444444446 Best Reward 332.0 Last Reward 182.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 205.3913043478261 Best Reward 332.0 Last Reward 203.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 205.6595744680851 Best Reward 332.0 Last Reward 218.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 205.35416666666666 Best Reward 332.0 Last Reward 191.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 205.6530612244898 Best Reward 332.0 Last Reward 220.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 176.0 Best Reward 332.0 Last Reward 176.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 229.0 Best Reward 332.0 Last Reward 282.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 214.0 Best Reward 332.0 Last Reward 184.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 204.0 Best Reward 332.0 Last Reward 174.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 202.4 Best Reward 332.0 Last Reward 196.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 218.66666666666666 Best Reward 332.0 Last Reward 300.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 212.0 Best Reward 332.0 Last Reward 172.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 217.5 Best Reward 332.0 Last Reward 256.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 213.0 Best Reward 332.0 Last Reward 177.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 213.1 Best Reward 332.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 219.8181818181818 Best Reward 332.0 Last Reward 287.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 218.5 Best Reward 332.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 216.92307692307693 Best Reward 332.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 213.78571428571428 Best Reward 332.0 Last Reward 173.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 209.8 Best Reward 332.0 Last Reward 154.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 207.5625 Best Reward 332.0 Last Reward 174.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 204.64705882352942 Best Reward 332.0 Last Reward 158.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 205.05555555555554 Best Reward 332.0 Last Reward 212.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 203.52631578947367 Best Reward 332.0 Last Reward 176.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 203.05 Best Reward 332.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 201.33333333333334 Best Reward 332.0 Last Reward 167.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 204.0909090909091 Best Reward 332.0 Last Reward 262.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 202.2608695652174 Best Reward 332.0 Last Reward 162.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 203.16666666666666 Best Reward 332.0 Last Reward 224.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 202.76 Best Reward 332.0 Last Reward 193.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 201.34615384615384 Best Reward 332.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 201.8148148148148 Best Reward 332.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 202.0 Best Reward 332.0 Last Reward 207.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 201.0 Best Reward 332.0 Last Reward 173.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 200.5 Best Reward 332.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 200.41935483870967 Best Reward 332.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 201.59375 Best Reward 332.0 Last Reward 238.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 202.03030303030303 Best Reward 332.0 Last Reward 216.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 202.85294117647058 Best Reward 332.0 Last Reward 230.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 202.28571428571428 Best Reward 332.0 Last Reward 183.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 202.91666666666666 Best Reward 332.0 Last Reward 225.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 203.45945945945945 Best Reward 332.0 Last Reward 223.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 204.23684210526315 Best Reward 332.0 Last Reward 233.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 205.82051282051282 Best Reward 332.0 Last Reward 266.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 205.05 Best Reward 332.0 Last Reward 175.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 205.90243902439025 Best Reward 332.0 Last Reward 240.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 206.02380952380952 Best Reward 332.0 Last Reward 211.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 205.46511627906978 Best Reward 332.0 Last Reward 182.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 207.8181818181818 Best Reward 332.0 Last Reward 309.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 207.9777777777778 Best Reward 332.0 Last Reward 215.0 Epsilon 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 46 Average Reward 208.5 Best Reward 332.0 Last Reward 232.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 208.29787234042553 Best Reward 332.0 Last Reward 199.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 209.125 Best Reward 332.0 Last Reward 248.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 208.9795918367347 Best Reward 332.0 Last Reward 202.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 209.0 Best Reward 332.0 Last Reward 209.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 232.5 Best Reward 332.0 Last Reward 256.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 227.33333333333334 Best Reward 332.0 Last Reward 217.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 229.75 Best Reward 332.0 Last Reward 237.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 229.8 Best Reward 332.0 Last Reward 230.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 221.16666666666666 Best Reward 332.0 Last Reward 178.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 217.28571428571428 Best Reward 332.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 220.125 Best Reward 332.0 Last Reward 240.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 232.44444444444446 Best Reward 332.0 Last Reward 331.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 226.8 Best Reward 332.0 Last Reward 176.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 224.36363636363637 Best Reward 332.0 Last Reward 200.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 225.66666666666666 Best Reward 332.0 Last Reward 240.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 224.6153846153846 Best Reward 332.0 Last Reward 212.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 223.28571428571428 Best Reward 332.0 Last Reward 206.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 219.46666666666667 Best Reward 332.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 218.5 Best Reward 332.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 218.35294117647058 Best Reward 332.0 Last Reward 216.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 216.16666666666666 Best Reward 332.0 Last Reward 179.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 214.78947368421052 Best Reward 332.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 214.15 Best Reward 332.0 Last Reward 202.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 212.04761904761904 Best Reward 332.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 212.86363636363637 Best Reward 332.0 Last Reward 230.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 213.65217391304347 Best Reward 332.0 Last Reward 231.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 215.375 Best Reward 332.0 Last Reward 255.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 213.96 Best Reward 332.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 211.96153846153845 Best Reward 332.0 Last Reward 162.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 211.7037037037037 Best Reward 332.0 Last Reward 205.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 216.03571428571428 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 217.6551724137931 Best Reward 333.0 Last Reward 263.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 216.06666666666666 Best Reward 333.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 215.25806451612902 Best Reward 333.0 Last Reward 191.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 217.15625 Best Reward 333.0 Last Reward 276.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 215.72727272727272 Best Reward 333.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 215.44117647058823 Best Reward 333.0 Last Reward 206.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 214.0857142857143 Best Reward 333.0 Last Reward 168.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 215.58333333333334 Best Reward 333.0 Last Reward 268.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 215.27027027027026 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 213.8684210526316 Best Reward 333.0 Last Reward 162.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 213.4102564102564 Best Reward 333.0 Last Reward 196.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 212.925 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 214.26829268292684 Best Reward 333.0 Last Reward 268.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 213.78571428571428 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 213.0 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 213.0909090909091 Best Reward 333.0 Last Reward 217.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 212.62222222222223 Best Reward 333.0 Last Reward 192.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 212.7826086956522 Best Reward 333.0 Last Reward 220.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 211.7872340425532 Best Reward 333.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 212.875 Best Reward 333.0 Last Reward 264.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 211.9591836734694 Best Reward 333.0 Last Reward 168.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 204.0 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 214.5 Best Reward 333.0 Last Reward 225.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 198.33333333333334 Best Reward 333.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 201.75 Best Reward 333.0 Last Reward 212.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 228.0 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 225.33333333333334 Best Reward 333.0 Last Reward 212.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 228.0 Best Reward 333.0 Last Reward 244.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 222.125 Best Reward 333.0 Last Reward 181.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 218.33333333333334 Best Reward 333.0 Last Reward 188.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 227.7 Best Reward 333.0 Last Reward 312.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 237.27272727272728 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 237.41666666666666 Best Reward 333.0 Last Reward 239.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 233.23076923076923 Best Reward 333.0 Last Reward 183.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 230.71428571428572 Best Reward 333.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 226.06666666666666 Best Reward 333.0 Last Reward 161.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 225.875 Best Reward 333.0 Last Reward 223.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 223.1764705882353 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 221.33333333333334 Best Reward 333.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 219.3684210526316 Best Reward 333.0 Last Reward 184.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 217.85 Best Reward 333.0 Last Reward 189.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 215.0 Best Reward 333.0 Last Reward 158.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 212.22727272727272 Best Reward 333.0 Last Reward 154.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 211.6086956521739 Best Reward 333.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 212.33333333333334 Best Reward 333.0 Last Reward 229.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 211.44 Best Reward 333.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 213.15384615384616 Best Reward 333.0 Last Reward 256.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 213.1851851851852 Best Reward 333.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 212.64285714285714 Best Reward 333.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 211.3448275862069 Best Reward 333.0 Last Reward 175.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 209.73333333333332 Best Reward 333.0 Last Reward 163.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 209.3548387096774 Best Reward 333.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 208.0 Best Reward 333.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 208.78787878787878 Best Reward 333.0 Last Reward 234.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 209.1764705882353 Best Reward 333.0 Last Reward 222.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 209.54285714285714 Best Reward 333.0 Last Reward 222.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 209.58333333333334 Best Reward 333.0 Last Reward 211.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 211.72972972972974 Best Reward 333.0 Last Reward 289.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 214.92105263157896 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 39 Average Reward 214.64102564102564 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 214.725 Best Reward 333.0 Last Reward 218.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 214.390243902439 Best Reward 333.0 Last Reward 201.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 213.85714285714286 Best Reward 333.0 Last Reward 192.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 214.13953488372093 Best Reward 333.0 Last Reward 226.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 212.72727272727272 Best Reward 333.0 Last Reward 152.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 212.8 Best Reward 333.0 Last Reward 216.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 212.17391304347825 Best Reward 333.0 Last Reward 184.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 211.3404255319149 Best Reward 333.0 Last Reward 173.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 211.83333333333334 Best Reward 333.0 Last Reward 235.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 212.0204081632653 Best Reward 333.0 Last Reward 221.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 227.0 Best Reward 333.0 Last Reward 227.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 195.5 Best Reward 333.0 Last Reward 164.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 204.33333333333334 Best Reward 333.0 Last Reward 222.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 205.25 Best Reward 333.0 Last Reward 208.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 208.4 Best Reward 333.0 Last Reward 221.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 203.33333333333334 Best Reward 333.0 Last Reward 178.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 204.14285714285714 Best Reward 333.0 Last Reward 209.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 202.75 Best Reward 333.0 Last Reward 193.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 201.33333333333334 Best Reward 333.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 203.5 Best Reward 333.0 Last Reward 223.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 199.54545454545453 Best Reward 333.0 Last Reward 160.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 197.83333333333334 Best Reward 333.0 Last Reward 179.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 200.69230769230768 Best Reward 333.0 Last Reward 235.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 210.14285714285714 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 212.13333333333333 Best Reward 333.0 Last Reward 240.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 210.5 Best Reward 333.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 209.52941176470588 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 208.33333333333334 Best Reward 333.0 Last Reward 188.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 208.68421052631578 Best Reward 333.0 Last Reward 215.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 214.9 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 220.52380952380952 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 221.8181818181818 Best Reward 333.0 Last Reward 249.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 220.7826086956522 Best Reward 333.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 218.75 Best Reward 333.0 Last Reward 172.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 218.52 Best Reward 333.0 Last Reward 213.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 218.1153846153846 Best Reward 333.0 Last Reward 208.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 216.11111111111111 Best Reward 333.0 Last Reward 164.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 215.5 Best Reward 333.0 Last Reward 199.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 215.9655172413793 Best Reward 333.0 Last Reward 229.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 216.56666666666666 Best Reward 333.0 Last Reward 234.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 214.8709677419355 Best Reward 333.0 Last Reward 164.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 214.28125 Best Reward 333.0 Last Reward 196.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 212.3939393939394 Best Reward 333.0 Last Reward 152.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 212.38235294117646 Best Reward 333.0 Last Reward 212.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 213.85714285714286 Best Reward 333.0 Last Reward 264.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 217.16666666666666 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 216.56756756756758 Best Reward 333.0 Last Reward 195.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 218.0 Best Reward 333.0 Last Reward 271.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 217.51282051282053 Best Reward 333.0 Last Reward 199.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 218.125 Best Reward 333.0 Last Reward 242.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 220.41463414634146 Best Reward 333.0 Last Reward 312.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 220.92857142857142 Best Reward 333.0 Last Reward 242.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 222.25581395348837 Best Reward 333.0 Last Reward 278.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 221.11363636363637 Best Reward 333.0 Last Reward 172.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 221.42222222222222 Best Reward 333.0 Last Reward 235.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 221.04347826086956 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 220.53191489361703 Best Reward 333.0 Last Reward 197.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 220.45833333333334 Best Reward 333.0 Last Reward 217.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 219.30612244897958 Best Reward 333.0 Last Reward 164.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 252.0 Best Reward 333.0 Last Reward 252.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 221.0 Best Reward 333.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 228.66666666666666 Best Reward 333.0 Last Reward 244.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 219.0 Best Reward 333.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 216.6 Best Reward 333.0 Last Reward 207.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 232.5 Best Reward 333.0 Last Reward 312.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 228.85714285714286 Best Reward 333.0 Last Reward 207.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 225.25 Best Reward 333.0 Last Reward 200.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 224.44444444444446 Best Reward 333.0 Last Reward 218.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 223.0 Best Reward 333.0 Last Reward 210.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 222.1818181818182 Best Reward 333.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 222.83333333333334 Best Reward 333.0 Last Reward 230.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 223.76923076923077 Best Reward 333.0 Last Reward 235.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 221.0 Best Reward 333.0 Last Reward 185.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 217.06666666666666 Best Reward 333.0 Last Reward 162.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 218.6875 Best Reward 333.0 Last Reward 243.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 225.41176470588235 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 224.61111111111111 Best Reward 333.0 Last Reward 211.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 226.10526315789474 Best Reward 333.0 Last Reward 253.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 224.6 Best Reward 333.0 Last Reward 196.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 226.57142857142858 Best Reward 333.0 Last Reward 266.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 231.0 Best Reward 333.0 Last Reward 324.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 227.7391304347826 Best Reward 333.0 Last Reward 156.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 226.41666666666666 Best Reward 333.0 Last Reward 196.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 225.52 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 226.80769230769232 Best Reward 333.0 Last Reward 259.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 225.25925925925927 Best Reward 333.0 Last Reward 185.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 223.5 Best Reward 333.0 Last Reward 176.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 225.13793103448276 Best Reward 333.0 Last Reward 271.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 226.83333333333334 Best Reward 333.0 Last Reward 276.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 228.06451612903226 Best Reward 333.0 Last Reward 265.0 Epsilon 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 32 Average Reward 226.5625 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 229.12121212121212 Best Reward 333.0 Last Reward 311.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 228.2941176470588 Best Reward 333.0 Last Reward 201.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 227.88571428571427 Best Reward 333.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 227.63888888888889 Best Reward 333.0 Last Reward 219.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 226.45945945945945 Best Reward 333.0 Last Reward 184.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 226.5 Best Reward 333.0 Last Reward 228.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 226.25641025641025 Best Reward 333.0 Last Reward 217.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 225.125 Best Reward 333.0 Last Reward 181.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 224.02439024390245 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 225.11904761904762 Best Reward 333.0 Last Reward 270.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 224.86046511627907 Best Reward 333.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 225.02272727272728 Best Reward 333.0 Last Reward 232.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 223.7111111111111 Best Reward 333.0 Last Reward 166.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 222.54347826086956 Best Reward 333.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 222.40425531914894 Best Reward 333.0 Last Reward 216.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 221.41666666666666 Best Reward 333.0 Last Reward 175.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 220.85714285714286 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 198.0 Best Reward 333.0 Last Reward 198.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 207.5 Best Reward 333.0 Last Reward 217.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 197.66666666666666 Best Reward 333.0 Last Reward 178.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 218.75 Best Reward 333.0 Last Reward 282.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 219.8 Best Reward 333.0 Last Reward 224.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 213.33333333333334 Best Reward 333.0 Last Reward 181.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 217.85714285714286 Best Reward 333.0 Last Reward 245.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 214.375 Best Reward 333.0 Last Reward 190.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 209.33333333333334 Best Reward 333.0 Last Reward 169.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 206.3 Best Reward 333.0 Last Reward 179.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 212.27272727272728 Best Reward 333.0 Last Reward 272.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 211.83333333333334 Best Reward 333.0 Last Reward 207.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 215.3846153846154 Best Reward 333.0 Last Reward 258.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 212.0 Best Reward 333.0 Last Reward 168.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 211.6 Best Reward 333.0 Last Reward 206.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 214.4375 Best Reward 333.0 Last Reward 257.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 214.23529411764707 Best Reward 333.0 Last Reward 211.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 212.55555555555554 Best Reward 333.0 Last Reward 184.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 210.31578947368422 Best Reward 333.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 212.6 Best Reward 333.0 Last Reward 256.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 212.38095238095238 Best Reward 333.0 Last Reward 208.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 212.36363636363637 Best Reward 333.0 Last Reward 212.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 212.6086956521739 Best Reward 333.0 Last Reward 218.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 213.0 Best Reward 333.0 Last Reward 222.0 Epsilon 0.001\n",
      "Episode 25 Average Reward 212.24 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 214.15384615384616 Best Reward 333.0 Last Reward 262.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 215.77777777777777 Best Reward 333.0 Last Reward 258.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 214.57142857142858 Best Reward 333.0 Last Reward 182.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 214.13793103448276 Best Reward 333.0 Last Reward 202.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 212.6 Best Reward 333.0 Last Reward 168.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 215.03225806451613 Best Reward 333.0 Last Reward 288.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 216.90625 Best Reward 333.0 Last Reward 275.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 216.93939393939394 Best Reward 333.0 Last Reward 218.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 216.91176470588235 Best Reward 333.0 Last Reward 216.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 216.5142857142857 Best Reward 333.0 Last Reward 203.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 216.86111111111111 Best Reward 333.0 Last Reward 229.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 215.86486486486487 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 217.23684210526315 Best Reward 333.0 Last Reward 268.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 216.89743589743588 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 217.075 Best Reward 333.0 Last Reward 224.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 216.85365853658536 Best Reward 333.0 Last Reward 208.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 215.92857142857142 Best Reward 333.0 Last Reward 178.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 217.88372093023256 Best Reward 333.0 Last Reward 300.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 217.47727272727272 Best Reward 333.0 Last Reward 200.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 216.44444444444446 Best Reward 333.0 Last Reward 171.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 215.93478260869566 Best Reward 333.0 Last Reward 193.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 215.2127659574468 Best Reward 333.0 Last Reward 182.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 214.45833333333334 Best Reward 333.0 Last Reward 179.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 213.73469387755102 Best Reward 333.0 Last Reward 179.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 174.0 Best Reward 333.0 Last Reward 174.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 208.0 Best Reward 333.0 Last Reward 242.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 203.0 Best Reward 333.0 Last Reward 193.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 212.75 Best Reward 333.0 Last Reward 242.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 218.6 Best Reward 333.0 Last Reward 242.0 Epsilon 0.001\n",
      "Episode 6 Average Reward 222.83333333333334 Best Reward 333.0 Last Reward 244.0 Epsilon 0.001\n",
      "Episode 7 Average Reward 228.57142857142858 Best Reward 333.0 Last Reward 263.0 Epsilon 0.001\n",
      "Episode 8 Average Reward 237.0 Best Reward 333.0 Last Reward 296.0 Epsilon 0.001\n",
      "Episode 9 Average Reward 233.55555555555554 Best Reward 333.0 Last Reward 206.0 Epsilon 0.001\n",
      "Episode 10 Average Reward 230.5 Best Reward 333.0 Last Reward 203.0 Epsilon 0.001\n",
      "Episode 11 Average Reward 231.54545454545453 Best Reward 333.0 Last Reward 242.0 Epsilon 0.001\n",
      "Episode 12 Average Reward 226.75 Best Reward 333.0 Last Reward 174.0 Epsilon 0.001\n",
      "Episode 13 Average Reward 225.76923076923077 Best Reward 333.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 14 Average Reward 221.78571428571428 Best Reward 333.0 Last Reward 170.0 Epsilon 0.001\n",
      "Episode 15 Average Reward 229.2 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 16 Average Reward 225.625 Best Reward 333.0 Last Reward 172.0 Epsilon 0.001\n",
      "Episode 17 Average Reward 222.94117647058823 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 18 Average Reward 222.0 Best Reward 333.0 Last Reward 206.0 Epsilon 0.001\n",
      "Episode 19 Average Reward 220.52631578947367 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 20 Average Reward 218.1 Best Reward 333.0 Last Reward 172.0 Epsilon 0.001\n",
      "Episode 21 Average Reward 216.28571428571428 Best Reward 333.0 Last Reward 180.0 Epsilon 0.001\n",
      "Episode 22 Average Reward 215.27272727272728 Best Reward 333.0 Last Reward 194.0 Epsilon 0.001\n",
      "Episode 23 Average Reward 213.47826086956522 Best Reward 333.0 Last Reward 174.0 Epsilon 0.001\n",
      "Episode 24 Average Reward 212.04166666666666 Best Reward 333.0 Last Reward 179.0 Epsilon 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 25 Average Reward 210.16 Best Reward 333.0 Last Reward 165.0 Epsilon 0.001\n",
      "Episode 26 Average Reward 211.1153846153846 Best Reward 333.0 Last Reward 235.0 Epsilon 0.001\n",
      "Episode 27 Average Reward 210.66666666666666 Best Reward 333.0 Last Reward 199.0 Epsilon 0.001\n",
      "Episode 28 Average Reward 212.64285714285714 Best Reward 333.0 Last Reward 266.0 Epsilon 0.001\n",
      "Episode 29 Average Reward 212.3793103448276 Best Reward 333.0 Last Reward 205.0 Epsilon 0.001\n",
      "Episode 30 Average Reward 212.26666666666668 Best Reward 333.0 Last Reward 209.0 Epsilon 0.001\n",
      "Episode 31 Average Reward 212.0 Best Reward 333.0 Last Reward 204.0 Epsilon 0.001\n",
      "Episode 32 Average Reward 211.84375 Best Reward 333.0 Last Reward 207.0 Epsilon 0.001\n",
      "Episode 33 Average Reward 211.87878787878788 Best Reward 333.0 Last Reward 213.0 Epsilon 0.001\n",
      "Episode 34 Average Reward 210.88235294117646 Best Reward 333.0 Last Reward 178.0 Epsilon 0.001\n",
      "Episode 35 Average Reward 212.31428571428572 Best Reward 333.0 Last Reward 261.0 Epsilon 0.001\n",
      "Episode 36 Average Reward 212.36111111111111 Best Reward 333.0 Last Reward 214.0 Epsilon 0.001\n",
      "Episode 37 Average Reward 215.32432432432432 Best Reward 333.0 Last Reward 322.0 Epsilon 0.001\n",
      "Episode 38 Average Reward 214.52631578947367 Best Reward 333.0 Last Reward 185.0 Epsilon 0.001\n",
      "Episode 39 Average Reward 213.74358974358975 Best Reward 333.0 Last Reward 184.0 Epsilon 0.001\n",
      "Episode 40 Average Reward 215.75 Best Reward 333.0 Last Reward 294.0 Epsilon 0.001\n",
      "Episode 41 Average Reward 216.29268292682926 Best Reward 333.0 Last Reward 238.0 Epsilon 0.001\n",
      "Episode 42 Average Reward 215.04761904761904 Best Reward 333.0 Last Reward 164.0 Epsilon 0.001\n",
      "Episode 43 Average Reward 216.53488372093022 Best Reward 333.0 Last Reward 279.0 Epsilon 0.001\n",
      "Episode 44 Average Reward 215.8409090909091 Best Reward 333.0 Last Reward 186.0 Epsilon 0.001\n",
      "Episode 45 Average Reward 215.51111111111112 Best Reward 333.0 Last Reward 201.0 Epsilon 0.001\n",
      "Episode 46 Average Reward 215.8695652173913 Best Reward 333.0 Last Reward 232.0 Epsilon 0.001\n",
      "Episode 47 Average Reward 216.10638297872342 Best Reward 333.0 Last Reward 227.0 Epsilon 0.001\n",
      "Episode 48 Average Reward 218.54166666666666 Best Reward 333.0 Last Reward 333.0 Epsilon 0.001\n",
      "Episode 49 Average Reward 218.71428571428572 Best Reward 333.0 Last Reward 227.0 Epsilon 0.001\n",
      "Episode 1 Average Reward 177.0 Best Reward 333.0 Last Reward 177.0 Epsilon 0.001\n",
      "Episode 2 Average Reward 204.5 Best Reward 333.0 Last Reward 232.0 Epsilon 0.001\n",
      "Episode 3 Average Reward 187.66666666666666 Best Reward 333.0 Last Reward 154.0 Epsilon 0.001\n",
      "Episode 4 Average Reward 190.75 Best Reward 333.0 Last Reward 200.0 Epsilon 0.001\n",
      "Episode 5 Average Reward 186.2 Best Reward 333.0 Last Reward 168.0 Epsilon 0.001\n"
     ]
    }
   ],
   "source": [
    "# Taking the gradient of the reward with respect to the temporal difference error\n",
    "agent.network.eval()\n",
    "\n",
    "best_reward = 0\n",
    "\n",
    "episode_number = []\n",
    "average_reward_number_attacked = []\n",
    "epsilons_attacks = [0,0.05, .1, 0.15, .2, 0.25, .3, 0.35, .4]\n",
    "\n",
    "\n",
    "for epsilon in epsilons_attacks:\n",
    "    average_reward_attacked = 0\n",
    "    for i in range(1,50):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        did_pertubate = 0\n",
    "        while True:\n",
    "            action, q_values = agent.choose_action(state)\n",
    "            state_, reward, done, info = env.step(action)\n",
    "\n",
    "            if score % 2 == 0 and not(isinstance(q_values,float)):\n",
    "                next_q_values = agent.network(state_.float()).detach()\n",
    "                loss = agent.network.loss(q_values, next_q_values)\n",
    "                gradient_sign = torch.autograd.grad(loss,state,retain_graph=True)[0].sign()\n",
    "                state = state + gradient_sign * epsilon\n",
    "                action, q_values = agent.choose_action(state)\n",
    "                state_, reward, done, info = env.step(action)\n",
    "                did_pertubate += 1\n",
    "\n",
    "            state = state_\n",
    "            score += reward\n",
    "\n",
    "            if done:            \n",
    "                if score > best_reward:\n",
    "                    best_reward = score\n",
    "                average_reward_attacked += score\n",
    "                print(\"Episode {} Average Reward {} Best Reward {} Last Reward {} Epsilon {}\".format(i, average_reward_attacked/i, best_reward, score, agent.returning_epsilon()))\n",
    "                break\n",
    "\n",
    "            episode_number.append(i)\n",
    "    average_reward_number_attacked.append(average_reward_attacked / i)\n",
    "    \n",
    "plt.ioff()\n",
    "plt.figure(1)\n",
    "plt.plot(epsilons_attacks,average_reward_number_attacked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f612ed",
   "metadata": {},
   "source": [
    "## Training the network with adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5a62f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_robust = DQN_Solver()\n",
    "agent_robust.network.train()\n",
    "\n",
    "best_reward = 0\n",
    "average_reward = 0\n",
    "episode_number = []\n",
    "average_reward_number = []\n",
    "\n",
    "for i in range(1, EPISODES):\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    while True:\n",
    "        action, q_values = agent_robust.choose_action(state)\n",
    "        state_, reward, done, info = env.step(action)\n",
    "        \n",
    "        if score % 2 == 0 and not(isinstance(q_values,float)):\n",
    "            next_q_values = agent_robust.network(state_.float()).detach()\n",
    "            loss = agent_robust.network.loss(q_values, next_q_values)\n",
    "            gradient_sign = torch.autograd.grad(loss,state,retain_graph=True)[0].sign()\n",
    "            state = state + gradient_sign * EPSILON_PERT\n",
    "            action, q_values = agent_robust.choose_action(state)\n",
    "            state_, reward, done, info = env.step(action)\n",
    "         \n",
    "                \n",
    "        agent_robust.memory.add(state, action, reward, state_, done)\n",
    "        agent_robust.learn()\n",
    "        state = state_\n",
    "        score += reward\n",
    "\n",
    "        if done:\n",
    "            if score > best_reward:\n",
    "                best_reward = score\n",
    "            average_reward += score\n",
    "            print(\"Episode {} Average Reward {} Best Reward {} Last Reward {} Epsilon {}\".format(i, average_reward/i, best_reward, score, agent.returning_epsilon()))\n",
    "            break\n",
    "\n",
    "        episode_number.append(i)\n",
    "        average_reward_number.append(average_reward/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217974c",
   "metadata": {},
   "source": [
    "## Testing the network with FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077251c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taking the gradient of the reward with respect to the temporal difference error\n",
    "agent_robust.network.eval()\n",
    "\n",
    "best_reward = 0\n",
    "\n",
    "episode_number = []\n",
    "average_reward_number_robust = []\n",
    "epsilons_attacks = [0,0.05, .1, 0.15, .2, 0.25, .3, 0.35, .4]\n",
    "\n",
    "\n",
    "for epsilon in epsilons_attacks:\n",
    "    average_reward_robust = 0\n",
    "    for i in range(1,50):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        while True:\n",
    "            action, q_values = agent_robust.choose_action(state)\n",
    "            state_, reward, done, info = env.step(action)\n",
    "\n",
    "            if score % 2 == 0 and not(isinstance(q_values,float)):\n",
    "                next_q_values = agent_robust.network(state_.float()).detach()\n",
    "                loss = agent_robust.network.loss(q_values, next_q_values)\n",
    "\n",
    "                gradient_sign = torch.autograd.grad(loss,state,retain_graph=True)[0].sign()\n",
    "                state = state + gradient_sign * epsilon\n",
    "                action, q_values = agent_robust.choose_action(state)\n",
    "                state_, reward, done, info = env.step(action)\n",
    "\n",
    "\n",
    "            state = state_\n",
    "            score += reward\n",
    "\n",
    "            if done:\n",
    "                if score > best_reward:\n",
    "                    best_reward = score\n",
    "                average_reward_robust += score\n",
    "                print(\"Episode {} Average Reward {} Best Reward {} Last Reward {} Epsilon {}\".format(i, average_reward_robust/i, best_reward, score, agent.returning_epsilon()))\n",
    "                break\n",
    "\n",
    "            episode_number.append(i)\n",
    "    average_reward_number_robust.append(average_reward_robust / i)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epsilons_attacks,average_reward_number_robust)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1f722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
